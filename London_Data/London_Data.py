# -*- coding: utf-8 -*-
"""udate_formative.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13LpL6d5JSjt7EmMQzWz861LxiJyep3Dm
"""

from google.colab import drive
drive.mount('/content/gdrive/', force_remount=True)

#pip install pyreadstat

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statistics
import pandas as pd
import pyreadstat as pr
import math 
from math import exp
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
from sklearn.model_selection import LeaveOneOut
from sklearn.metrics import accuracy_score
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif
from sklearn import linear_model
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, roc_curve

#Load London District codes.csv file
df_district = pd.read_csv("/content/gdrive/MyDrive/datasets_udate/raw/dist_code.csv")
#print all the data
df_district

#Check duplication
duplicate_district = df_district[df_district.duplicated()]
duplicate_district

"""Since there is no duplicate row in District data, we can proceed to load the other data."""

#Load London ward data environment.csv
df_ward_environment = pd.read_csv("/content/gdrive/MyDrive/datasets_udate/raw/env.csv")
df_ward_environment.info()

#Check duplication
duplicate_environment = df_ward_environment[df_ward_environment.duplicated()]
duplicate_environment

#Check column completeness
print((df_ward_environment['Wardcode'].values == '').sum())
print((df_ward_environment['Population2011Census'].values == 0).sum())
print((df_ward_environment['Crimerate'].values == 0).sum())
print((df_ward_environment['Openspace'].values == 0).sum())

#Check the Openspace column with 0 value
open_null = df_ward_environment.query("Openspace == 0", engine="python")
open_null

"""As it is possible for a ward not to have an open space, so we are not going to impute the value."""

#Print the first five data
df_ward_environment.head()

#Since we are going to proceed further with the Wardcode data, then check if there is anomaly
df_ward_environment.Wardcode.astype(str).str.len().unique()

#As it can be seen from df_ward_environment.head(), the sampel shows that each Wardcode's value are 6 length chars
#So we have to find out the one with 8 length
anomaly = df_ward_environment.query("Wardcode.str.len() == 8", engine="python")
anomaly

#Remove the ag chars from the 00BAGDag so it became 00BAGD
df_ward_environment['Wardcode'] = df_ward_environment['Wardcode'].str.replace('00BAGDag','00BAGD')

#Load London ward data socioeconomic.sav file
df_ward_socioeconomic=pd.read_spss('/content/gdrive/MyDrive/datasets_udate/raw/socio.sav')
df_ward_socioeconomic.info()

#Check duplication
duplicate_socioeconomic = df_ward_socioeconomic[df_ward_socioeconomic.duplicated()]
duplicate_socioeconomic

#Check column completeness
print((df_ward_socioeconomic['Wardcode'].values == '').sum())
print((df_ward_socioeconomic['hhSocialRented'].values == 0).sum())
print((df_ward_socioeconomic['JobSeekers'].values == 0).sum())
print((df_ward_socioeconomic['Noqual'].values == 0).sum())
print((df_ward_socioeconomic['Carsperhousehold'].values == 0).sum())

#Remove row which does not have wardcode
df_ward_socioeconomic = df_ward_socioeconomic[df_ward_socioeconomic.Wardcode != '']

#Since we are going to proceed further with the Wardcode data, then check if there is anomaly
df_ward_socioeconomic.Wardcode.astype(str).str.len().unique()

#As it can be seen from df_ward_environment.head(), the sampel shows that each Wardcode's value are 6 length chars
#So we have to find out the one with 8 length
anomaly = df_ward_socioeconomic.query("Wardcode.str.len() == 7", engine="python")
anomaly

#Remove the # char from the 00AGGK# so it became 00AGGK
df_ward_socioeconomic['Wardcode'] = df_ward_socioeconomic['Wardcode'].str.replace('#','')

#Check how many Wardcode are not the same from Socioeconomic and Environment 
check_wardcode = df_ward_socioeconomic[~df_ward_socioeconomic['Wardcode'].isin(df_ward_environment['Wardcode'])]
check_wardcode

"""As it can be seen, that the Wardcode from Socioeconomic data are precisely similar with those from Environment data."""

#Combine Socioeconomic and Environment by Wardcode
df_merge_ward_environment_socioeconomic = pd.merge(df_ward_environment, df_ward_socioeconomic, how="outer", on=["Wardcode"])
df_merge_ward_environment_socioeconomic

#Load london ward data health.sas7bdat file
df_ward_data_health, meta = pr.read_sas7bdat('/content/gdrive/MyDrive/datasets_udate/raw/health.sas7bdat')
df_ward_data_health.head()

#Check column completeness
print((df_ward_data_health['Wardname'].values == '').sum())
print((df_ward_data_health['Population2011Census'].values == 0).sum())
print((df_ward_data_health['GeneralFertilityRate'].values == 0).sum())
print((df_ward_data_health['Malelifeexpectancy'].values == 0).sum())
print((df_ward_data_health['Femalelifeexpectancy'].values == 0).sum())

#Check duplicate data
duplicate_health = df_ward_data_health[df_ward_data_health.duplicated()]
duplicate_health

#Check the Wardname column unique value
#df_ward_data_health['Wardname'] = df_ward_data_health['Wardname'].astype('str').str.replace(' ','')
df_ward_data_health['Wardname'].unique()

#Load London ward data demographics.dat file
df_demographics = pd.read_csv('/content/gdrive/MyDrive/datasets_udate/raw/demo.dat', sep='\t', lineterminator='\r')
df_demographics.head()

#Check column completeness
print((df_demographics['Wardname'].values == '').sum())
print((df_demographics['Greaterthan65'].values == 0).sum())
print((df_demographics['nonwhite'].values == 0).sum())
print((df_demographics['NotBorninUK'].values == 0).sum())
print((df_demographics['NotEnglishspeaking'].values == 0).sum())

#It is obvious that there is \n char in front of every Wardname, so we must remove it first
df_demographics['Wardname'] = df_demographics['Wardname'].str.replace('\n','')

df_demographics['Wardname'].unique()

#It is obvious that there are two different chars or symbols between Wardname in Health data and in Demographic data\
#First, in Demograhic, it uses "&" instead of "and", as in District data it uses "and", so we replace "&" with "and"
df_demographics['Wardname'] = df_demographics['Wardname'].astype('str').str.replace('&','and')
#Second, in Demographic, it uses "Saint", and in Health it uses St., so we replace "Saint" with "St."
df_demographics['Wardname'] = df_demographics['Wardname'].str.replace('Saint','St.')
#Check if it has been replaced
df_demographics['Wardname'].unique()

#Check how many Wardcode are not the same from Health and Demographic
check_wardname = df_ward_data_health[~df_ward_data_health['Wardname'].isin(df_demographics['Wardname'])]
check_wardname

#Combine Socioeconomic and Environment by Wardname
df_merge_ward_health_demographics = pd.merge(df_ward_data_health, df_demographics, how="outer", on=["Wardname"])
df_merge_ward_health_demographics

#As we will use the Population Cencus later to combine values, we have to drop those will NaN value
df_merge_ward_health_demographics = df_merge_ward_health_demographics.dropna()
df_merge_ward_health_demographics

#Since we have the district and district code only as reference, we try to get district name from ward name that is seperated by "-"
df_merge_ward_health_demographics[['District','Ward']] = df_merge_ward_health_demographics['Wardname'].astype('str').str.split(' - ', 1, expand=True)
#As we only need the district, we can drop the Ward
df_merge_ward_health_demographics = df_merge_ward_health_demographics.drop('Ward', axis=1)
df_merge_ward_health_demographics['District'] = df_merge_ward_health_demographics['District'].astype('str').str.replace(' ','')
#Print the district
df_merge_ward_health_demographics

df_district['District'] = df_district['District'].astype('str').str.replace(' ','')

#Check how many District are not the same from Health and Demographic data compare to District data
check_district = df_merge_ward_health_demographics[~df_merge_ward_health_demographics['District'].isin(df_district['District'])]
check_district

df_merge_ward_health_demographics_district = pd.merge(df_merge_ward_health_demographics, df_district, how="outer", on=["District"])
#df_merge_ward_health_demographics_district = df_merge_ward_health_demographics_district.dropna()
df_merge_ward_health_demographics_district

"""Now we have two data that have not been linked. We will link them using a new ID called MyID that combine District Code and its population."""

#First, create MyID from Environment and Socioeconomic data
#Create the District code column, take the first four digit from Wardcode column
df_merge_ward_environment_socioeconomic['Districtcode'] = df_merge_ward_environment_socioeconomic['Wardcode'].astype('str').str.replace(' ','').str[:4]
#Create MyID Column by combining District code and Population cencus
df_merge_ward_environment_socioeconomic['MyID'] = df_merge_ward_environment_socioeconomic['Districtcode'].str.replace(' ','') + df_merge_ward_environment_socioeconomic['Population2011Census'].astype(str)
df_merge_ward_environment_socioeconomic['MyID'] = df_merge_ward_environment_socioeconomic['MyID'].astype('str') + ".0"
df_merge_ward_environment_socioeconomic['MyID'] = df_merge_ward_environment_socioeconomic['MyID'].astype('str').str.replace(' ','')
df_merge_ward_environment_socioeconomic

#And then, create MyID from Health and Demographic data
#Create MyID Column by combining District code and Population cencus
df_merge_ward_health_demographics_district['MyID'] = df_merge_ward_health_demographics_district['Districtcode'] + df_merge_ward_health_demographics_district['Population2011Census'].astype(str)
df_merge_ward_health_demographics_district['MyID'] = df_merge_ward_health_demographics_district['MyID'].astype('str').str.replace(' ','')
df_merge_ward_health_demographics_district

#Check how many Wardcode are the same from Socioeconomic and Environment compare to Helalth and Demographics
test = df_merge_ward_environment_socioeconomic[~df_merge_ward_environment_socioeconomic['MyID'].isin(df_merge_ward_health_demographics_district['MyID'])]
test

#Combine the data so it is integrated
df_merge_all = pd.merge(df_merge_ward_environment_socioeconomic, df_merge_ward_health_demographics_district, how="outer", on=["MyID"])
df_merge_all.head()

df_merge_all = df_merge_all.dropna()
df_merge_all

df_merge_all = df_merge_all.drop(['Population2011Census_x','Districtcode_x','MyID','Districtcode_y','District'], axis=1)
df_merge_all

df_merge_all = df_merge_all.rename(columns={"Population2011Census_y": "Population2011Census"})
df_merge_all

df_merge_all = df_merge_all[['Wardcode', 'Wardname', 'Malelifeexpectancy', 'Femalelifeexpectancy','Openspace','hhSocialRented','JobSeekers','Noqual','Carsperhousehold','Population2011Census','GeneralFertilityRate','Children','Greaterthan65','nonwhite','NotBorninUK','NotEnglishspeaking']]
df_merge_all

df_male = df_merge_all.drop(['Femalelifeexpectancy','Wardcode','Wardname'],axis=1)
df_male.head()

#sns.pairplot(df_male)

df_female = df_merge_all.drop(['Malelifeexpectancy','Wardcode','Wardname'],axis=1)
df_female

#sns.pairplot(df_female)

#Draw Heatmap
corrmat = df_male.corr()

fig, ax = plt.subplots(figsize=(13,13))
hm = sns.heatmap(corrmat, 
                 cbar=True, 
                 annot=True, 
                 square=True, 
                 fmt='.2f', 
                 yticklabels=df_male.columns, 
                 xticklabels=df_male.columns)
plt.show()

#Create function for selecting best features to predict the best model
def select_features(X_train, y_train, X_test):
    # configure to select all features
    fs = SelectKBest(score_func=f_classif, k='all')
    # learn relationship from training data
    fs.fit(X_train, y_train)
    # transform train input data
    X_train_fs = fs.transform(X_train)
    # transform test input data
    X_test_fs = fs.transform(X_test)
    return X_train_fs, X_test_fs, fs

#Select the best features to predict the best model
df_copy = df_male.copy()
df_copy = df_copy.drop(columns=['Malelifeexpectancy'],axis=1)
X = df_copy.values
y = df_male['Malelifeexpectancy'].values 
X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.1, random_state=50)
X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)
# what are scores for the features
for i in range(len(fs.scores_)):
    print('Feature %d: %f' % (i, fs.scores_[i]))
# plot the scores
plt.bar([i for i in range(len(fs.scores_))], fs.scores_)
plt.show()

from sklearn.metrics import mean_squared_error, r2_score

# Train-test split
X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y,  test_size=0.1, random_state=0)

# Builds the classifier
lin2 = LinearRegression()

# Fitting the data
lin2 = lin2.fit(X_train2, y_train2)

# Predicting the data
y_pred2 = lin2.predict(X_test2)

# Evaluates on the test data
print("Mean squared error: %.2f" % mean_squared_error(y_test2, y_pred2))
# The coefficient of determination: 1 is perfect prediction
print("Coefficient of determination: %.2f" % r2_score(y_test2, y_pred2))

from sklearn.ensemble import RandomForestRegressor

Model = RandomForestRegressor(n_estimators=50)
Model = Model.fit(X_train2, y_train2)
y_pred3 = Model.predict(X_test2)
print("Mean squared error: %.2f" % mean_squared_error(y_test2, y_pred3))
# The coefficient of determination: 1 is perfect prediction
print("Coefficient of determination: %.2f" % r2_score(y_test2, y_pred3))

#Draw Heatmap
corrmat = df_female.corr()

fig, ax = plt.subplots(figsize=(13,13))
hm = sns.heatmap(corrmat, 
                 cbar=True, 
                 annot=True, 
                 square=True, 
                 fmt='.2f', 
                 yticklabels=df_female.columns, 
                 xticklabels=df_female.columns)
plt.show()

#Select the best features to predict the best model
df_copy = df_female.copy()
df_copy = df_copy.drop(columns=['Femalelifeexpectancy'],axis=1)
X = df_copy.values
y = df_female['Femalelifeexpectancy'].values 
X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.1, random_state=50)
X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)
# what are scores for the features
for i in range(len(fs.scores_)):
    print('Feature %d: %f' % (i, fs.scores_[i]))
# plot the scores
plt.bar([i for i in range(len(fs.scores_))], fs.scores_)
plt.show()

# Train-test split
X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y,  test_size=0.1, random_state=0)

# Builds the classifier
lin2 = LinearRegression()

# Fitting the data
lin2 = lin2.fit(X_train2, y_train2)

# Predicting the data
y_pred2 = lin2.predict(X_test2)

# Evaluates on the test data
print("Mean squared error: %.2f" % mean_squared_error(y_test2, y_pred2))
# The coefficient of determination: 1 is perfect prediction
print("Coefficient of determination: %.2f" % r2_score(y_test2, y_pred2))